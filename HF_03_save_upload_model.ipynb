{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Kt7T8WtlZD202oPCheJoXuhEMiICSCJd","timestamp":1713416203331}],"gpuType":"T4","authorship_tag":"ABX9TyMTlxNmUxMcKSgHYehKl9TG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Create model and do inference"],"metadata":{"id":"x94NFxmDgIKh"}},{"cell_type":"code","source":["# it will be useful if we want to fine tune our model\n","\n","import torch\n","import torch.nn.functional as F\n","from transformers import pipeline\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","inputs = [\"I've been waiting for this movie my whole life!\", \"This movie is fantastic!\"]\n","\n","batch = tokenizer(inputs, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")   # tokenization\n","with torch.no_grad():       # inference, no gradient descent\n","  output = model(**batch)                          # feed token to the model\n","  predictions = F.softmax(output.logits, dim=1)    # run the model\n","  labels = torch.argmax(predictions, dim=1)        # return the result\n","  print(labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DyPX_NwKXban","executionInfo":{"status":"ok","timestamp":1713415637332,"user_tz":240,"elapsed":1614,"user":{"displayName":"Min Chen","userId":"17937423999888765307"}},"outputId":"c548afa7-d479-4b04-9e82-389d7c67ab38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 1])\n"]}]},{"cell_type":"markdown","source":["## Save model"],"metadata":{"id":"QHB967KWkjLK"}},{"cell_type":"code","source":["save_directory = \"saved\"\n","tokenizer.save_pretrained(save_directory)\n","model.save_pretrained(save_directory)"],"metadata":{"id":"1nRX1JqHi1uq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Upload model"],"metadata":{"id":"NbFFkSPKkptj"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","save_directory = \"saved\"\n","tok = AutoTokenizer.from_pretrained(save_directory)\n","mod = AutoModelForSequenceClassification.from_pretrained(save_directory)"],"metadata":{"id":"hXq5Epewjqq7"},"execution_count":null,"outputs":[]}]}