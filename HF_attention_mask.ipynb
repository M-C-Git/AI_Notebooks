{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPX4jPGrOOO2oMkFAaYE7bQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# What is fed to model? <br>\n","We do not just fed model with sequence of token ids, but put it in a batch container. <br>\n","sequence: tensor([2023,  3185, 19237,   999]) <br>\n","batch container: tensor([[2023,  3185, 19237,   999]]) <br>"],"metadata":{"id":"2tK0UrWps1qo"}},{"cell_type":"code","source":["# the codes will run into error at line 13, because the input tensor is 1D, only a sequence token, not a batch which is 2D\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","\n","checkpoint = \"allevelly/Movie_Review_Sentiment_Analysis\"\n","raw_text1 = \"This movie is scary!\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","token = tokenizer.tokenize(raw_text1)\n","token_ids = tokenizer.convert_tokens_to_ids(token)   # one dimension list\n","input_ids = torch.tensor(token_ids)                  # one dimension tensor\n","print(token_ids, input_ids, sep='\\n')\n","model(input_ids)      # error, because we only fed the model with sequence which is in 1D tensor, instead of 2D batch\n","\n","#==============================================\n","# Batching is to put multiple sentences in one container, and pass through the model altogether all at once.\n","# Even if you only have one sentence, you still need to put it in a batch container.\n","#=============================================="],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"IUdS6gqIvGKt","executionInfo":{"status":"error","timestamp":1713759731128,"user_tz":240,"elapsed":700,"user":{"displayName":"Min Chen","userId":"17937423999888765307"}},"outputId":"27c421e3-3dc1-4a6c-9b2e-cfce2d611385"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["[2023, 3185, 2003, 12459, 999]\n","tensor([ 2023,  3185,  2003, 12459,   999])\n"]},{"output_type":"error","ename":"IndexError","evalue":"too many indices for tensor of dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-77-e273ee40ee39>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# one dimension tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# error, because we only fed the model with sequence which is in 1D tensor, instead of 2D batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#==============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m   1003\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mwarn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4168\u001b[0m         \u001b[0;31m# Check only the first and last input IDs to reduce overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4169\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4170\u001b[0m             warn_string = (\n\u001b[1;32m   4171\u001b[0m                 \u001b[0;34m\"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"]}]},{"cell_type":"code","source":["# correct the error by adding one more dimention to the input tesnor\n","input_ids = torch.tensor([token_ids])   # we add one more dimension to token_ids by put it in a list\n","print(input_ids)                        # input_ids is becoming 2D tensor, which is a batch.\n","model(input_ids).logits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsKi47nrxTWO","executionInfo":{"status":"ok","timestamp":1713759682346,"user_tz":240,"elapsed":150,"user":{"displayName":"Min Chen","userId":"17937423999888765307"}},"outputId":"be40cc23-1615-404b-c4de-3a18219c4550"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 2023,  3185,  2003, 12459,   999]])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.6172,  1.9445]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":75}]},{"cell_type":"markdown","source":["# Attnesion Mask\n"],"metadata":{"id":"F_OlfyXkxKYn"}},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvLDXhYbss3F","executionInfo":{"status":"ok","timestamp":1713759619011,"user_tz":240,"elapsed":319,"user":{"displayName":"Min Chen","userId":"17937423999888765307"}},"outputId":"18a01f58-b5ca-4553-c481-1d4d10e44c68"},"outputs":[{"output_type":"stream","name":"stdout","text":["['[CLS]', 'this', 'movie', 'is', 'scary', '!', 'great', '!', '[SEP]']\n","---------------input tensors----------------\n","tensor([[  101,  2023,  3185,  2003, 12459,   999,  2307,   999,   102]])\n","tensor([[  101,  2023,  3185,  2003, 12459,   999,   102]])\n","tensor([[  101,  2023,  3185,  2003, 12459,   999,  2307,   999,   102],\n","        [  101,  2023,  3185,  2003, 12459,   999,   102,     0,     0]])\n","---------------model logits----------------\n","tensor([[-2.3800,  2.7929]], grad_fn=<AddmmBackward0>)\n","tensor([[-1.7340,  2.0677]], grad_fn=<AddmmBackward0>)\n","tensor([[-2.3800,  2.7929],\n","        [-1.5437,  1.8513]], grad_fn=<AddmmBackward0>)\n"]}],"source":["# comparing the results with attention mask and without.\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","\n","checkpoint = \"allevelly/Movie_Review_Sentiment_Analysis\"\n","raw_text1 = \"This movie is scary! Great!\"\n","raw_text2 = \"This movie is scary!\"\n","raw_text_batch = [raw_text1, raw_text2]\n","\n","token_text1 = [\"[CLS]\"] + tokenizer.tokenize(raw_text1) + [\"[SEP]\"]  # add special token to match tokenizer()\n","token_ids_text1 = tokenizer.convert_tokens_to_ids(token_text1)\n","input_ids_text1 = torch.tensor([token_ids_text1])\n","\n","token_text2 = [\"[CLS]\"] + tokenizer.tokenize(raw_text2) + [\"[SEP]\"]  # add special token to match tokenizer()\n","token_ids_text2 = tokenizer.convert_tokens_to_ids(token_text2)\n","input_ids_text2 = torch.tensor([token_ids_text2])\n","\n","output = tokenizer(raw_text_batch, padding=True)\n","input_ids_batch = torch.tensor(output.input_ids)\n","print(tokenizer.convert_ids_to_tokens(input_ids_batch[0]))\n","\n","print ('---------------input tensors----------------')\n","print (input_ids_text1, input_ids_text2, input_ids_batch, sep='\\n')\n","\n","print ('---------------model logits----------------')\n","print(model(input_ids_text1).logits)\n","print(model(input_ids_text2).logits)\n","print(model(input_ids_batch).logits)"]},{"cell_type":"markdown","source":["From the above printing output, we conclude:\n","1. raw_text1 has the same classfication result, as the input tensors are the same in individual and in batch.\n","2. raw_text2 has different classfication results, as the input tensor in batch has more zeros comparing to in individual.\n","The zeros are the padding, to screen out the padding, we need attention mask."],"metadata":{"id":"YV9IjeLM7BPv"}},{"cell_type":"code","source":["# add attention ask to batch to make raw_text2 model output the same.\n","attention_mask = [list(0 if ele.item()==0 else 1 for ele in input_ids) for input_ids in input_ids_batch]\n","print(attention_mask)\n","\n","print(model(input_ids_batch,\n","            attention_mask=torch.tensor(attention_mask)).logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJt-gEfH79NO","executionInfo":{"status":"ok","timestamp":1713759633250,"user_tz":240,"elapsed":151,"user":{"displayName":"Min Chen","userId":"17937423999888765307"}},"outputId":"cbcb6ecc-20c4-42bc-e6c8-4fbd06551254"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0]]\n","tensor([[-2.3800,  2.7929],\n","        [-1.7340,  2.0677]], grad_fn=<AddmmBackward0>)\n"]}]}]}