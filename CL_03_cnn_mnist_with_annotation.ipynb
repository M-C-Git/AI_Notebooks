{"cells":[{"cell_type":"markdown","metadata":{"id":"FRHut93vCcIs"},"source":["# Importing Necessary Libraries\n","In this block, we're importing all the necessary modules and libraries. This includes modules for data processing, model building, and visualization."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPzrOmNN3G76"},"outputs":[],"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from google.colab import files"]},{"cell_type":"markdown","metadata":{"id":"kqPmlWTKCjR9"},"source":["#Loading the MNIST Dataset\n","The MNIST dataset contains handwritten digits. We're dividing the data into training and test sets. The training set (train_images and train_labels) is used to train the model, and the test set (test_images and test_labels) is used to evaluate its performance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OM-Xno4OCju0"},"outputs":[],"source":["# Load the dataset\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"]},{"cell_type":"markdown","metadata":{"id":"HlfuMumwCwg4"},"source":["#Data Preprocessing\n","For the neural network to work effectively, the image data is normalized to a range between 0 and 1. This is achieved by dividing each pixel value by 255 (maximum pixel value). Next, we reshape the images to include a single channel (grayscale) because CNNs expect a 3D matrix as input for each image."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IHS2z1rZCxBU"},"outputs":[],"source":["# Normalize the images to be between 0 and 1 and reshape them\n","train_images = train_images.astype('float32') / 255.0\n","test_images = test_images.astype('float32') / 255.0\n","train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n","test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"]},{"cell_type":"markdown","metadata":{"id":"oQl69t0PDCob"},"source":["# Label Processing\n","Our labels are digits from 0 to 9. However, the neural network will output an array of probabilities (one for each class). By converting the labels to one-hot encoded format, we make sure the label format matches the output format of the network."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaeUd9V_Jvm2"},"outputs":[],"source":["# Convert labels to one-hot encoded format\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)"]},{"cell_type":"markdown","metadata":{"id":"rpYaZPmDDUGS"},"source":["#Building the CNN Model\n","Here, we define the architecture of our convolutional neural network:\n","\n","Conv2D Layer: Convolutional layer with 32 filters of size 3x3 and ReLU activation. This layer will learn local patterns in the data.\n","MaxPooling2D Layer: Reduces the spatial dimensions by taking the maximum value in each window of size 2x2.\n","Another Conv2D Layer with 64 filters to learn more complex patterns.\n","Another MaxPooling2D for dimensionality reduction.\n","Flatten: This layer reshapes the 3D output of the previous layer to 1D.\n","Dense Layer: A fully connected layer with 128 neurons and ReLU activation.\n","Dropout: Randomly sets 50% of the input units to 0 at each update during training, which helps to prevent overfitting.\n","Dense Layer: The final layer with 10 neurons (one for each class) and a softmax activation to output class probabilities."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVglR6ZrDDAg"},"outputs":[],"source":["# Instantiate a Sequential model\n","model = Sequential()\n","\n","# Add layers one by one\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(10, activation='softmax'))"]},{"cell_type":"markdown","metadata":{"id":"2ITcK5zvDnlC"},"source":["#Compiling the Model\n","Before training, we need to define how the model should learn. We specify:\n","\n","Optimizer: The algorithm that will be used to optimize the weights. 'Adam' is a popular choice.\n","Loss Function: Since it's a multi-class classification, we use categorical_crossentropy as the loss function.\n","Metrics: We're interested in the accuracy of classification, so we include 'accuracy' as a metric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfPEnTT2EZiy"},"outputs":[],"source":["model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"cXTTb6jKESHb"},"source":["#Training the Model\n","Now, we're training the model using our training data. The model's weights are updated in a way to minimize the loss over 5 epochs. Each epoch is a complete forward and backward pass of all the training examples.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04uimzUJDp6T","outputId":"a55877ec-a337-4437-8aa3-db0961c126be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 60s 32ms/step - loss: 0.2164 - accuracy: 0.9347\n","Epoch 2/5\n","1875/1875 [==============================] - 49s 26ms/step - loss: 0.0834 - accuracy: 0.9755\n","Epoch 3/5\n","1875/1875 [==============================] - 53s 28ms/step - loss: 0.0589 - accuracy: 0.9825\n","Epoch 4/5\n","1875/1875 [==============================] - 52s 28ms/step - loss: 0.0466 - accuracy: 0.9859\n","Epoch 5/5\n","1875/1875 [==============================] - 53s 28ms/step - loss: 0.0408 - accuracy: 0.9875\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7ad4790a06a0>"]},"metadata":{},"execution_count":21}],"source":["# Train the model\n","model.fit(train_images, train_labels, epochs=5, batch_size=32)"]},{"cell_type":"markdown","metadata":{"id":"4VG8MQJLEfT8"},"source":["#Saving the Trained Model\n","After training, we save the model's architecture and its weights to a file. This allows us to load the trained model later without having to retrain it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qsWlsfJ7Ej7Z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0340bc40-1106-4471-9a4c-16ada80bed32"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["# Save the trained model\n","model.save('mnist_cnn_model.h5')"]},{"cell_type":"markdown","metadata":{"id":"gyFn0a_yE5ih"},"source":["<details>\n","<summary># Evaluating the Model on Test Data</summary>\n","\n","**Explanation:**\n","After training the model, it's crucial to evaluate its performance on unseen data, which is our test dataset. The `model.evaluate()` method returns the model's loss and other metrics (in this case, accuracy) on the test dataset.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJ-bTlQ1FBkx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bfc49ca8-330c-4196-81ef-d5ce95df08b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 4s 11ms/step - loss: 0.0239 - accuracy: 0.9922\n","Test accuracy: 0.9922000169754028\n","Test loss: 0.02388986013829708\n"]}],"source":["test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n","print(f'Test accuracy: {test_accuracy}')\n","print(f'Test loss: {test_loss}')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}